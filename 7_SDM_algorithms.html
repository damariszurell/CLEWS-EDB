<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>SDM algorithms</title>

<script src="site_libs/header-attrs-2.13/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Ecosystem dynamics and biodiversity</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pracs: Spatial data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="0_setup.html">0. Getting started</a>
    </li>
    <li>
      <a href="1_SpatialData.html">1. Spatial data in R</a>
    </li>
    <li>
      <a href="2_BiodivData.html">2. Biodiversity data in R</a>
    </li>
    <li>
      <a href="3_ThreatData.html">3. Threat data in R</a>
    </li>
    <li>
      <a href="4_EnvData.html">4. Environmental data in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pracs: Species distribution models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="5_SDM_intro.html">5. SDMs: simple model fitting</a>
    </li>
    <li>
      <a href="6_SDM_eval.html">6. SDMs: assessment and prediction</a>
    </li>
    <li>
      <a href="7_SDM_algorithms.html">7. SDMs: algorithms and ensembles</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pracs: population modelling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="8_RS_intro.html">8. Getting started with RangeShiftR</a>
    </li>
    <li>
      <a href="9_RS_lynx.html">9. RangeShiftR: Eurasian lynx reintroduction</a>
    </li>
    <li>
      <a href="10_RS_grouse.html">10. RangeShiftR: Black grouse range dynamics</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pracs: ecosystem modelling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="11_Mad_intro.html">11. Running MadingleyR</a>
    </li>
    <li>
      <a href="12_Mad_carnivores.html">12. MadingleyR: Role of large carnivores</a>
    </li>
    <li>
      <a href="13_Mad_landuse.html">13. MadingleyR: land use change effects</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://www.uni-potsdam.de/en/ibb-macroecology/index">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/ZurellLab">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">SDM algorithms</h1>

</div>


<div class="alert alert-info">
<p><strong>RStudio project</strong></p>
<p>Open the RStudio project that we created in the first session. I
recommend to use this RStudio project for the entire course and within
the RStudio project create separate R scripts for each session.</p>
<ul>
<li>Create a new empty R script by going to the tab “File”, select “New
File” and then “R script”</li>
<li>In the new R script, type
<code># Session 7: SDM algorithms and ensembles</code> and save the file
in your folder “scripts” within your project folder, e.g. as
“7_SDM_algorithms.R”</li>
</ul>
</div>
<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>So far, we have learnt to fit GLMs to species presence-absence data.
GLMs are only one, very simple parametric method for fitting SDMs. There
are many more algorithms out there <span class="citation">(Elith et al.
2006; Thuiller et al. 2009; Guisan, Thuiller, and Zimmermann
2017)</span>. Here, we will get to know a few of them. Remember the five
general model building steps: (i) conceptualisation, (ii) data
preparation, (iii) model fitting, (iv) assessment and (v) predictions
<span class="citation">(Zurell, Franklin, et al. 2020)</span>. These are
the same for all SDMs independent of the particular algorithm used. In
this tutorial, we will concentrate on model fitting again but will also
run model assessments and make predictions in order to compare the
different algorithms.</p>
<div id="recap-of-last-session-data-and-model-building-steps"
class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Recap of last
session: data and model building steps</h2>
<p>I will illustrate the different algorithms using the lynx example of
sessions 5-6. The species presense/absence data and the bioclimatic
variables at these locations are available from file. Also, remember
that we have already tested the data for multicollinearity and
identified bio11 and bio10 as weakly correlated variables with high
univariate variable importance.</p>
<pre class="r"><code>library(raster)
load(&#39;data/lynx_thinned.RData&#39;)

my_preds &lt;- c(&#39;bio11&#39;, &#39;bio10&#39;)</code></pre>
<p>In session 6 on model assessment, we learned that the models should
be validated on indepedent validation data and we have learned how to
run a 5-fold cross-validation. The <code>crossvalSDM()</code> function
could also be used with the algorithms introduced in this practical.
However, to simplify matters let’s rather split the data into training
data and testing data once. For a proper validation this split-sample
should be repeated many times. Nevertheless, this unique split-sample
will still give us an idea of model performance and will allow us to
compare the different algorithms.</p>
<pre class="r"><code>set.seed(54321)

# First, we randomly select 70% of the rows that will be used as training data
train_i &lt;- sample(seq_len(nrow(lynx_thinned)), size=round(0.7*nrow(lynx_thinned)))

# Then, we can subset the training and testing data
lynx_train &lt;- lynx_thinned[train_i,]
lynx_test &lt;- lynx_thinned[-train_i,]

# We store the split information for later:
write(train_i, file=&#39;data/indices_traindata.txt&#39;)</code></pre>
<p>For making predictions in space, we also load the current climate
layers that we downloaded previously.</p>
<pre class="r"><code>bio_curr &lt;- getData(&quot;worldclim&quot;, var=&quot;bio&quot;, res=10, download=F, path=&#39;data/clim_data&#39;)</code></pre>
<p>We again crop the climate data to European extent and aggregate them
to 1° resolution.</p>
<pre class="r"><code># rough European extent
extent_eur &lt;- c(-15,45,35,72)

# Crop data to European extent
bio_curr &lt;- crop(bio_curr, extent_eur)

# Aggregate to 1° resolution
bio_curr &lt;- aggregate(bio_curr, 6)</code></pre>
</div>
</div>
<div id="model-algorithms" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Model algorithms</h1>
<p>Typically, you should decide on appropriate modelling algorithms
during the conceptualisation phase. Let’s assume our study objectives
were to compare species-environment relationships and predicted species
distributions across several SDM algorithms, for example to quantify the
uncertainty due to the model class <span class="citation">(Araujo and
New 2007; Thuiller et al. 2009; Buisson et al. 2010)</span>. We will
test several different SDM algorithms that can be broadly classified
into profile (envelope and distance-based) methods, regression-based
methods and non-parametric machine-learning methods <a
href="http://rspatial.org/sdm/rst/6_sdm_methods.html"><span
class="citation">Guisan, Thuiller, and Zimmermann (2017)</span></a>. We
only cover four different algorithms here; for more example have a look
at our <a
href="https://damariszurell.github.io/EEC-MGC/b6_SDM_algorithms.html">Macroecology
module</a>.</p>
<div id="profile-envelope-and-distance-based-methods"
class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Profile (envelope and
distance-based) methods</h2>
<p>Profile methods constitute the oldest family of SDM algorithms and
are the only “true” presence-only methods that do not need any absence
or background data, but rely on envelope or distance-based
approaches.</p>
<div id="bioclim" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> BIOCLIM</h3>
<p>BIOCLIM is a pioneering envelope approach <span
class="citation">(Booth et al. 2014)</span>. It defines the niche as an
<em>n</em>-dimensional, rectangular bounding box, which is similar to
Hutchinson’s view of the <em>n</em>-dimensional hyperspace <span
class="citation">(Hutchinson 1957)</span>. To reduce sensitivity to
outliers, the bounding box can be limited by only considering a certain
percentile range (e.g. 5-95%) of the species records along each
environmental gradient. In <code>dismo</code>, the BIOCLIM algorithm is
implemented such that it will produce continuous probabilities between 0
and 1, indicating how similar/close the environmental conditions are to
the median conditions.</p>
<pre class="r"><code>library(dismo)

# Fit BIOCLIM model
m_bc &lt;- bioclim(bio_curr[[my_preds]], # provide environmental raster
                lynx_train[lynx_train$occ==1,1:2]) # provide coordinates of presence locations
plot(m_bc)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The resulting plot shows the bounding box (5-95% percentile range).
The red cross within the box is the median. We can also visualise this a
response surface to get a better idea what BIOCLIM is predicting.</p>
<pre class="r"><code># For the response surface, we first prepare the 3D-grid with environmental gradient and predictions
xyz &lt;- expand.grid(
    seq(min(lynx_train[,my_preds[1]]),max(lynx_train[,my_preds[1]]),length=50),
    seq(min(lynx_train[,my_preds[2]]),max(lynx_train[,my_preds[2]]),length=50))
names(xyz) &lt;- my_preds
# Make predictions to gradients:
xyz$z &lt;- predict(m_bc, xyz)

# Define colour palette:
library(RColorBrewer)
cls &lt;- colorRampPalette(rev(brewer.pal(11, &#39;RdYlBu&#39;)))(100)

# Plot response surface:
library(lattice)
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;BIOCLIM&#39;, xlab=&#39;bio11&#39;, ylab=&#39;bio10&#39;, 
          screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>We nicely see the median as the peak of the surface, representing the
median environmental conditions in presence locations. Let’s look at the
corresponding partial response plots.</p>
<pre class="r"><code>library(mecofun)

# Plot partial response curves:
par(mfrow=c(1,2)) 
partial_response(m_bc, predictors = lynx_train[,my_preds], main=&#39;BIOCLIM&#39;)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Last, we validate model performance on the hold-out test data.</p>
<pre class="r"><code># We use the default MaxSens+Spec threshold:
(perf_bc &lt;- evalSDM(lynx_test$occ, predict(m_bc, lynx_test[,my_preds])))</code></pre>
<pre><code>##         AUC       TSS     Kappa      Sens      Spec       PCC         D2 thresh
## 1 0.8711117 0.5979092 0.5963128 0.7735849 0.8243243 0.8031496 -0.2000966   0.11</code></pre>
<p>Finally, let’s map the predicted occurrence probabilities across
Britain and the predicted presence/absence.</p>
<pre class="r"><code># Map predictions:
r_bc_pred &lt;- r_bc_bin &lt;- predict(m_bc,bio_curr)

# Threshold predictions using the maxTSS threshold (max sens+spec)
values(r_bc_bin) &lt;- ifelse(values(r_bc_pred)&gt;=perf_bc$thresh, 1, 0)

# plot the maps
plot(stack(r_bc_pred, r_bc_bin),main=c(&#39;BIOCLIM prob.&#39;,&#39;BIOCLIM bin.&#39;), axes=F) </code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="regression-based-methods" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Regression-based
methods</h2>
<div id="generalised-linear-models-glms" class="section level3"
number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Generalised linear
models (GLMs)</h3>
<p>We already know GLMs from the previous tutorials. We can fit linear,
quadratic or higher polynomial terms (check <code>poly()</code>) and
interactions between predictors.</p>
<pre class="r"><code># Fit GLM
m_glm &lt;- step(glm( occ ~ bio11 + I(bio11^2) + bio10 + I(bio10^2),
    family=&#39;binomial&#39;, data=lynx_train))</code></pre>
<pre><code>## Start:  AIC=189.26
## occ ~ bio11 + I(bio11^2) + bio10 + I(bio10^2)
## 
##              Df Deviance    AIC
## - I(bio11^2)  1   179.44 187.44
## &lt;none&gt;            179.26 189.26
## - I(bio10^2)  1   206.69 214.69
## - bio10       1   207.08 215.08
## - bio11       1   217.02 225.02
## 
## Step:  AIC=187.44
## occ ~ bio11 + bio10 + I(bio10^2)
## 
##              Df Deviance    AIC
## &lt;none&gt;            179.44 187.44
## - I(bio10^2)  1   207.52 213.52
## - bio10       1   208.02 214.02
## - bio11       1   268.86 274.86</code></pre>
<pre class="r"><code># Now, we plot the response surface:
xyz$z &lt;- predict(m_glm, xyz, type=&#39;response&#39;)

wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;GLM&#39;, xlab=&#39;bio11&#39;, ylab=&#39;bio10&#39;, 
          screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code># Plot partial response curves:
par(mfrow=c(1,2)) 
partial_response(m_glm, predictors = lynx_train[,my_preds], main=&#39;GLM&#39;)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<pre class="r"><code># Performance measures
(perf_glm &lt;- evalSDM(lynx_test$occ, predict(m_glm, lynx_test[,my_preds], type=&#39;response&#39;) ))</code></pre>
<pre><code>##        AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.936512 0.7437532 0.7538442 0.8113208 0.9324324 0.8818898 0.5162029   0.48</code></pre>
<pre class="r"><code># Map predictions:
bio_curr_df &lt;- data.frame(rasterToPoints(bio_curr[[my_preds]]))
r_glm_bin &lt;- r_glm_pred &lt;- rasterFromXYZ(cbind(bio_curr_df[,1:2],
                                  predict(m_glm, bio_curr_df, type=&#39;response&#39;)))
values(r_glm_bin) &lt;- ifelse(values(r_glm_pred)&gt;=perf_glm$thresh, 1, 0)
plot(stack(r_glm_pred, r_glm_bin),main=c(&#39;GLM prob.&#39;,&#39;GLM bin.&#39;), axes=F)   </code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-11-3.png" width="672" /></p>
</div>
</div>
<div id="machine-learning-methods" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Machine-learning
methods</h2>
<p>There are a number of different non-parametric machine-learning
methods that are commonly used in SDMs, and new methods are constantly
appearing. A few methods like Classification and Regression Trees (CART)
and Artificial Neural Networks (ANN) have been around for some time,
while other methods such as Boosted Regression Trees (BRTs), Random
Forests (RFs) and Maximum Entropy (MaxEnt) have only become popular over
the last decade.</p>
<div id="random-forests-rfs" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Random Forests
(RFs)</h3>
<p>Regression models or classification models can be affected by local
optima and noise in the data. They usually have low bias (fit the
training data very well) but high variance (noisy/poorer performance
when predicting to non-training data). Model averaging has been proposed
as possible solution <span class="citation">(Hastie, Tibshirani, and
Friedman 2009)</span>. In recent years, so-called bagging and boosting
methods have been developed for combining or averaging different models.
Random Forests use a bagging procedure for averaging the outputs of a
multitude of different CARTs (Classification and Regression Trees).
Bagging stands for “bootstrap aggregation”. Basically, we fit many CARTs
to bootstrapped samples of the training data and then either average the
results in case of regression trees or make a simple vote in case of
classification trees (committee averaging)<span
class="citation">(Hastie, Tibshirani, and Friedman 2009; Guisan,
Thuiller, and Zimmermann 2017)</span>. An important feature of Random
Forests are the out-of-bag samples, which means that the predictions/fit
for a specific data point is only derived from averaging trees that did
not include this data point during tree growing. Thus, the output of
Random Forests is essentially cross-validated. Random Forests estimate
variable importance by a permutation procedure, which measures for each
variable the drop in mean accuracy when this variables is
permutated.</p>
<pre class="r"><code>library(randomForest)

# Fit RF
m_rf &lt;- randomForest( x=lynx_train[,my_preds], y=lynx_train$occ, 
    ntree=1000, importance =T)
    
# Variable importance:
importance(m_rf,type=1)</code></pre>
<pre><code>##        %IncMSE
## bio11 92.58769
## bio10 44.73107</code></pre>
<pre class="r"><code>varImpPlot(m_rf)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code># Look at single trees:
head(getTree(m_rf,1,T))</code></pre>
<pre><code>##   left daughter right daughter split var split point status prediction
## 1             2              3     bio11   -22.11111     -3 0.29729730
## 2             4              5     bio10   176.73611     -3 0.59859155
## 3             6              7     bio10   205.01389     -3 0.01948052
## 4             8              9     bio11  -116.71569     -3 0.70175439
## 5            10             11     bio11   -23.59722     -3 0.17857143
## 6            12             13     bio10   204.04167     -3 0.03947368</code></pre>
<pre class="r"><code># Now, we plot the response surface:
xyz$z &lt;- predict(m_rf, xyz, type=&#39;response&#39;)
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Random Forest&#39;, xlab=&#39;bio11&#39;, ylab=&#39;bio10&#39;, 
          screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
<pre class="r"><code># Plot partial response curves:
par(mfrow=c(1,2)) 
partial_response(m_rf, predictors = lynx_train[,my_preds], main=&#39;Random Forest&#39;)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-12-3.png" width="672" /></p>
<pre class="r"><code># Performance measures of RF
(perf_rf &lt;- evalSDM(lynx_test$occ, predict(m_rf, lynx_test[,my_preds],  type=&#39;response&#39;) ))</code></pre>
<pre><code>##         AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.9535951 0.7598164 0.7577877 0.8679245 0.8918919 0.8818898 0.5817348  0.355</code></pre>
<pre class="r"><code># Map predictions:
r_rf_bin &lt;- r_rf_pred &lt;- rasterFromXYZ(cbind(bio_curr_df[,1:2],
                                 predict(m_rf, bio_curr_df,type=&#39;response&#39;)))
values(r_rf_bin) &lt;- ifelse(values(r_rf_pred)&gt;=perf_rf$thresh, 1, 0)
plot(stack(r_rf_pred, r_rf_bin),main=c(&#39;RF prob.&#39;,&#39;RF bin.&#39;), axes=F)   </code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-12-4.png" width="672" /></p>
</div>
<div id="boosted-regression-trees-brts" class="section level3"
number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Boosted regression
trees (BRTs)</h3>
<p>Boosting is another averaging/ensemble approach for improving the
predictive performance of models <span class="citation">(Hastie,
Tibshirani, and Friedman 2009; Guisan, Thuiller, and Zimmermann
2017)</span>. Boosting of CARTS is known under different names including
Gradient Boosting Machine (GBM), Generalised Boosted Regression Model
(GBM) and Boosted Regression Trees (BRTs) among others. In R it is
available in the package <em>gbm</em> with some additional functions
from <span class="citation">Elith, Leathwick, and Hastie (2008)</span>
provided in the <em>dismo</em> package. <span class="citation">Elith,
Leathwick, and Hastie (2008)</span> also provide a working guide for
using BRTs in species distribution modelling. Unlike Random Forests,
BRTs iteratively fit relatively simple trees by putting emphasis on
observations fitted poorly by the previous trees (by fitting the new
tree to the residuals of the previous tree). The final BRT can be
thought of as linear combination of all trees, similar to a regression
model where each term is a single tree <span class="citation">(Elith,
Leathwick, and Hastie 2008)</span>. Thereby each tree is shrunk by the
learning rate (the shrinkage parameter, typically &lt;1), which
determines how much weight is given to single trees. Generally, slower
learning (meaning smaller learning rates) are preferable. Similarly to
Random Forests, only a subset of the data (the <em>bag fraction</em>) is
used for fitting consecutive trees (but in contrast to Random Forests,
the subsets are sampled without replacement and thus constitute real
data splits). This <em>bag fraction</em> should typically range 0.5-0.75
<span class="citation">(Elith, Leathwick, and Hastie 2008)</span>. The
tree complexity controls the interaction depth; <code>1</code> means
only tree stumps (with two terminal nodes) are fitted, <code>2</code>
means a model with up to two-way interactions etc. In the regular
<code>gbm()</code>function, you have to define the maximum number of
trees fitted. <span class="citation">Elith, Leathwick, and Hastie
(2008)</span> recommend fitting at least 1000 trees. However, you want
to be careful not to overfit the model by fitting too many trees. The
<em>dismo</em> package provides the function <code>gbm.step</code> that
selects the optimum number of trees based on the reduction in deviance
achieved by adding a tree while predicting to the hold-out data
(1-<code>bag fraction</code>). If the optimal number of trees estimated
by the model is below 1000, you should decrease your learning rate; if
it is above 10000, you should increase your learning rate. A tutorial on
BRTs is contained in the dismo package: <code>vignette('brt')</code></p>
<pre class="r"><code>library(gbm)

# Fit BRT
m_brt &lt;- gbm.step(data = lynx_train, 
    gbm.x = my_preds,
    gbm.y = &#39;occ&#39;, 
    family = &#39;bernoulli&#39;,
    tree.complexity = 2,
    bag.fraction = 0.75,
    learning.rate = 0.001,
    verbose=F)</code></pre>
<pre><code>## 
##  
##  GBM STEP - version 2.9 
##  
## Performing cross-validation optimisation of a boosted regression tree model 
## for NA and using a family of bernoulli 
## Using 296 observations and 2 predictors 
## creating 10 initial models of 50 trees 
## 
##  folds are stratified by prevalence 
## total mean deviance =  1.1867 
## tolerance is fixed at  0.0012 
## now adding trees...</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code># Variable importance:
m_brt$contributions</code></pre>
<pre><code>##         var  rel.inf
## bio11 bio11 73.65121
## bio10 bio10 26.34879</code></pre>
<pre class="r"><code># Interactions (not very meaningful here with only 2 predictors):
gbm.interactions(m_brt)$interactions</code></pre>
<pre><code>##       bio11  bio10
## bio11     0 101.95
## bio10     0   0.00</code></pre>
<pre class="r"><code>gbm.interactions(m_brt)$rank.list</code></pre>
<pre><code>##   var1.index var1.names var2.index var2.names int.size
## 1          2      bio10          1      bio11   101.95
## 2          3       &lt;NA&gt;          0                0.00</code></pre>
<pre class="r"><code># Now, we plot the response surface:
xyz$z &lt;- predict.gbm(m_brt, xyz, n.trees=m_brt$gbm.call$best.trees, type=&quot;response&quot;)
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Boosted regression trees&#39;, xlab=&#39;bio11&#39;, 
          ylab=&#39;bio10&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<pre class="r"><code># Plot partial response curves:
par(mfrow=c(1,2)) 
partial_response(m_brt, predictors = lynx_train[,my_preds], main=&#39;BRT&#39;)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-13-3.png" width="672" /></p>
<pre class="r"><code># Performance measures of BRT
(perf_brt &lt;- evalSDM(lynx_test$occ, predict.gbm(m_brt, lynx_test[,my_preds], n.trees=m_brt$gbm.call$best.trees, type=&#39;response&#39;) ))</code></pre>
<pre><code>##         AUC      TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.9507904 0.754462 0.7564873 0.8490566 0.9054054 0.8818898 0.5545085   0.39</code></pre>
<pre class="r"><code># Map predictions:
r_brt_bin &lt;- r_brt_pred &lt;- rasterFromXYZ(cbind(bio_curr_df[,1:2],
                                  predict.gbm(m_brt, bio_curr_df,
                                              n.trees=m_brt$gbm.call$best.trees, 
                                              type=&quot;response&quot;)))
values(r_brt_bin) &lt;- ifelse(values(r_brt_pred)&gt;=perf_brt$thresh, 1, 0)
plot(stack(r_brt_pred, r_brt_bin),main=c(&#39;BRT prob.&#39;,&#39;BRT bin.&#39;), axes=F)   </code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-13-4.png" width="672" /></p>
</div>
</div>
<div id="comparing-all-algorithms" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Comparing all
algorithms</h2>
<p>We can now compare the performance of all algorithms on our
independent data.</p>
<pre class="r"><code>(comp_perf &lt;- rbind(bc = perf_bc, glm = perf_glm, rf = perf_rf, brt = perf_brt))</code></pre>
<pre><code>##           AUC       TSS     Kappa      Sens      Spec       PCC         D2
## bc  0.8711117 0.5979092 0.5963128 0.7735849 0.8243243 0.8031496 -0.2000966
## glm 0.9365120 0.7437532 0.7538442 0.8113208 0.9324324 0.8818898  0.5162029
## rf  0.9535951 0.7598164 0.7577877 0.8679245 0.8918919 0.8818898  0.5817348
## brt 0.9507904 0.7544620 0.7564873 0.8490566 0.9054054 0.8818898  0.5545085
##     thresh
## bc   0.110
## glm  0.480
## rf   0.355
## brt  0.390</code></pre>
<pre class="r"><code># We add a column containing the names of the algorithm
comp_perf &lt;- data.frame(alg=row.names(comp_perf),comp_perf)

# Adapt the file path to your folder structure
write.table(comp_perf, file=&#39;data/SDM_alg_performances.txt&#39;, row.names=F)</code></pre>
</div>
</div>
<div id="model-ensembles" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Model ensembles</h1>
<p>But how do we proceed with all these models now? In the end, it would
be handy to just work with a single, general prediction. One way to
achive a single prediction would be to select the best performing
algorithm. However, we have also seen that different models make
different assumptions and extrapolate differently to new environments.
<em>A priori</em>, it is difficult to judge which of the algorithms will
perform best in new situations. Ensemble models have been introduced as
an alternative <span class="citation">(Araujo and New 2007)</span>.
These combine different models and provide information about the overall
trend and the uncertainty around this trend <span
class="citation">(Guisan, Thuiller, and Zimmermann 2017; Thuiller et al.
2019)</span>. Sometimes, the term ensembles is used synonymously with
model averaging <span class="citation">(Dormann et al. 2018)</span> when
only different model algorithms are combined. According to <span
class="citation">Araujo and New (2007)</span>, ensembles could also take
into account varying initial and boundary conditions (e.g. different
data inputs, and different future scenarios).</p>
<p>In ensembles, predictions can be combined or averaged in different
ways <span class="citation">(Thuiller et al. 2009)</span>. Simple
averages of predictions are derived using the arithmetic mean or the
median. An alternative is to use weighted averages. Here, each model
receives a weight derived from information criteria (e.g. AIC) or from
predictive performance (e.g. AUC or TSS derived from cross-validation or
split-sample approaches). To assess uncertainty in model predictions, we
can, for example, calculate the coefficient of variation or standard
deviation.</p>
<p>Here, we will concentrate on how different algorithms can be combined
into ensemble predictions. This is primarily meant to show you the main
workflow. The ensembles can be adopted individually by using less, more
or simply other algorithms, by using different parameterisations for the
different algorithms, by using different input data (e.g. atlas data
vs. range maps), and projections can be made to different scenarios of
future (or past) global change.</p>
<p>There is one important note for forecast ensembles. Typically, we
would make projections under climate change or land use change for
scenarios derived from different climate models or land use models. This
captures the uncertainty from different underlying model assumptions.
This should not be confused with different storylines (the old SRES
storylines or newer RCPs in climate models, or the SSPs in land use
models; <span class="citation">Vuuren and Carter (2013)</span>). When
making projections into the future, we would typically combine ensembles
of predictions for different SDM algorithms and different climate and
land use models. However, we would not combine projections for different
storylines, but would want to analyse the potential pathways
separately.</p>
<div id="single-model-predictions" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Single model
predictions</h2>
<p>We first derive the predictions for each single model algorithms -
here, we predict to independent test data:</p>
<pre class="r"><code>pred_testdata &lt;- data.frame(
  bc = predict(m_bc, lynx_test[,my_preds]),
  glm = predict(m_glm, lynx_test[,my_preds], type=&#39;response&#39;),
  rf = predict(m_rf, lynx_test[,my_preds], type=&#39;response&#39;),
  brt = predict.gbm(m_brt, lynx_test[,my_preds], 
                         n.trees=m_brt$gbm.call$best.trees, type=&quot;response&quot;)
)

summary(pred_testdata)</code></pre>
<pre><code>##        bc               glm                rf               brt         
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.02173  
##  1st Qu.:0.00000   1st Qu.:0.03077   1st Qu.:0.01358   1st Qu.:0.04313  
##  Median :0.07229   Median :0.34724   Median :0.23708   Median :0.26286  
##  Mean   :0.16175   Mean   :0.37964   Mean   :0.37398   Mean   :0.37504  
##  3rd Qu.:0.25301   3rd Qu.:0.71118   3rd Qu.:0.75949   3rd Qu.:0.72364  
##  Max.   :0.89157   Max.   :0.96016   Max.   :0.99780   Max.   :0.94510</code></pre>
<p>As we have stored the maxSens+Spec threshold for each model, we can
also threshold the predictions to obtain predicted presences and
absences.</p>
<pre class="r"><code># We use the sapply function to apply the thresholding to all columns 
# in the prediction data frame. You could also use a loop or construct
# the data frame by hand.
binpred_testdata &lt;- sapply(names(pred_testdata), FUN=function(alg){ 
  ifelse(pred_testdata[,alg]&gt;=comp_perf[comp_perf$alg==alg,&#39;thresh&#39;],1,0)
})

summary(binpred_testdata)</code></pre>
<pre><code>##        bc              glm              rf              brt        
##  Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :0.0000   Median :0.000   Median :0.0000   Median :0.0000  
##  Mean   :0.4252   Mean   :0.378   Mean   :0.4252   Mean   :0.4094  
##  3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000</code></pre>
</div>
<div id="making-ensembles" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Making ensembles</h2>
<p>We have gathered all information now that we need for making
ensembles: evaluation statistics, optimal thresholds for binary
predictions, and model predictions. The predictions can be combined into
ensembles in different ways:<br />
- mean of probabilities<br />
- median of probabilities<br />
- weighted mean of probabilities (weighted by model performance)<br />
- committee averaging of binary predictions (what is the proportion of
models predicting a presence?)</p>
<pre class="r"><code># Mean of probabilities
mean_prob &lt;- rowMeans(pred_testdata)

# Median of probabilities
median_prob &lt;- apply(pred_testdata, 1, median)

# Weighted mean of probabilities, weighted by TSS 
# (Make sure that order of models is the same in df for predictions and performance!!)
wmean_prob &lt;- apply(pred_testdata, 1, weighted.mean, w=comp_perf[,&#39;TSS&#39;])

# Committee averaging of binary predictions: calculates the proportion of
# models that predict the species to be present.
committee_av &lt;- rowSums(binpred_testdata)/ncol(binpred_testdata)

# We can also calculate uncertainty measures, 
# e.g. the standard deviation when making ensembles of mean probabilities.
sd_prob &lt;- apply(pred_testdata, 1, sd)</code></pre>
<p>Thus, ensembles can be easily constructed by hand. Of course, if you
have many input data, models, and scenarios to put into your ensemble,
this is easily becoming tedious. For that purpose, it will be very
useful to automatise your code and write automatic functions. For an
example for automatising your functions, have a look at the code that we
published along with <span class="citation">Zurell, Zimmermann, et al.
(2020)</span>, which you can obtain from the corresponding <a
href="https://github.com/damariszurell/SSDM-JSDM">github repository</a>.
Also, there are packages like <code>biomod2</code> that make it easy to
construct ensembles automatically <span class="citation">(Thuiller et
al. 2009)</span>.</p>
<p>Now, let’s assess the performance of these ensembles.</p>
<pre class="r"><code># performance measures for &quot;mean of probabilities&quot;
(perf_mean_prob &lt;- evalSDM(lynx_test$occ, mean_prob))</code></pre>
<pre><code>##         AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.9525752 0.7840388 0.7757316 0.9056604 0.8783784 0.8897638 0.5037352   0.31</code></pre>
<pre class="r"><code># performance measures for &quot;median of probabilities&quot;:
(perf_median_prob &lt;- evalSDM(lynx_test$occ, median_prob))</code></pre>
<pre><code>##         AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.9523202 0.7758797 0.7616068 0.9245283 0.8513514 0.8818898 0.5481092   0.28</code></pre>
<pre class="r"><code># performance measures for &quot;weighted mean of probabilities&quot;:
(perf_wmean_prob &lt;- evalSDM(lynx_test$occ, wmean_prob))</code></pre>
<pre><code>##       AUC       TSS     Kappa      Sens      Spec       PCC        D2 thresh
## 1 0.95436 0.7840388 0.7757316 0.9056604 0.8783784 0.8897638 0.5157303   0.32</code></pre>
<pre class="r"><code># Compare:
(ens_perf &lt;- rbind(mean_prob = perf_mean_prob, median_prob = perf_median_prob, 
                    wmean_prob = perf_mean_prob))</code></pre>
<pre><code>##                   AUC       TSS     Kappa      Sens      Spec       PCC
## mean_prob   0.9525752 0.7840388 0.7757316 0.9056604 0.8783784 0.8897638
## median_prob 0.9523202 0.7758797 0.7616068 0.9245283 0.8513514 0.8818898
## wmean_prob  0.9525752 0.7840388 0.7757316 0.9056604 0.8783784 0.8897638
##                    D2 thresh
## mean_prob   0.5037352   0.31
## median_prob 0.5481092   0.28
## wmean_prob  0.5037352   0.31</code></pre>
<pre class="r"><code># Note that we do not assess the performance of the committee average as the interpretation of this ensemble is quite different: it gives the proportion of models that agree on predicted presence</code></pre>
</div>
<div id="visualising-response-surfaces" class="section level2"
number="3.3">
<h2><span class="header-section-number">3.3</span> Visualising response
surfaces</h2>
<p>Let’s plot the response surfaces for the ensembles.</p>
<pre class="r"><code># Response surfaces:
# Make predictions of all models to hypothetical grid:
xyz_preds &lt;- data.frame(
  bc = predict(m_bc, xyz),
  glm = predict(m_glm, xyz, type=&#39;response&#39;),
  rf = predict(m_rf, xyz, type=&#39;response&#39;),
  brt = predict.gbm(m_brt, xyz, 
                         n.trees=m_brt$gbm.call$best.trees, type=&quot;response&quot;)
)

# Make binary predictions
xyz_bin &lt;- sapply(names(xyz_preds), FUN=function(alg){ 
  ifelse(xyz_preds[,alg]&gt;=comp_perf[comp_perf$alg==alg,&#39;thresh&#39;],1,0)
})

# Make ensembles:
xyz_ensemble &lt;- data.frame(
  mean_prob = rowMeans(xyz_preds),
  median_prob = apply(xyz_preds, 1, median),
  wmean_prob = apply(xyz_preds, 1, weighted.mean, w=comp_perf[,&#39;TSS&#39;]),
  committee_av = rowSums(xyz_bin)/ncol(xyz_bin),
  sd_prob = apply(xyz_preds, 1, sd)
)   

# Plot ensemble of mean probabilities:
xyz$z &lt;- xyz_ensemble[,&#39;mean_prob&#39;]
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: mean prob&#39;, xlab=&#39;bio11&#39;, 
          ylab=&#39;bio10&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre class="r"><code># Plot ensemble of median probabilities:
xyz$z &lt;- xyz_ensemble[,&#39;median_prob&#39;]
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: median prob&#39;, xlab=&#39;bio11&#39;, 
          ylab=&#39;bio10&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-19-2.png" width="672" /></p>
<pre class="r"><code># Plot ensemble of weighted mean probabilities:
xyz$z &lt;- xyz_ensemble[,&#39;wmean_prob&#39;]
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: weighted mean prob&#39;, xlab=&#39;bio11&#39;, 
          ylab=&#39;bio10&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-19-3.png" width="672" /></p>
<pre class="r"><code># Plot ensemble of committee average. This provides the proportion of models that agree on predicted presence:
xyz$z &lt;- xyz_ensemble[,&#39;committee_av&#39;]
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: committee average&#39;, xlab=&#39;bio11&#39;, 
          ylab=&#39;bio10&#39;, screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-19-4.png" width="672" /></p>
<pre class="r"><code># Plot standard deviation of mean probabilities. This gives us an indication where in environmental space we have highest uncertainty:
xyz$z &lt;- xyz_ensemble[,&#39;sd_prob&#39;]
wireframe(z ~ bio11 + bio10, data = xyz, zlab = list(&quot;Occurrence prob.&quot;, rot=90), 
          drape = TRUE, col.regions = cls, scales = list(arrows = FALSE), 
          zlim = c(0, 1), main=&#39;Ensemble: sd&#39;, xlab=&#39;bio11&#39;, ylab=&#39;bio10&#39;, 
          screen=list(z = -120, x = -70, y = 3))</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-19-5.png" width="672" /></p>
</div>
<div id="mapping-ensemble-predictions" class="section level2"
number="3.4">
<h2><span class="header-section-number">3.4</span> Mapping ensemble
predictions</h2>
<p>Finally, let’s do some mapping. We first map the occurrence
probabilities predicted by the different algorithms as well as the
potential presences.</p>
<pre class="r"><code># Prepare data frame with environmental data
bio_curr_df &lt;- data.frame(rasterToPoints(bio_curr[[my_preds]]))

# We make predictions of all models:
env_preds &lt;- data.frame(bio_curr_df[,1:2], 
  bc = predict(m_bc, bio_curr_df),
  glm = predict(m_glm, bio_curr_df, type=&#39;response&#39;),
  rf = predict(m_rf, bio_curr_df, type=&#39;response&#39;),
  brt = predict.gbm(m_brt, bio_curr_df, 
                         n.trees=m_brt$gbm.call$best.trees, type=&quot;response&quot;))
                        

# Binarise predictions of all algorithms
env_preds_bin &lt;- data.frame(bio_curr_df[,1:2],
  sapply(names(env_preds[,-c(1:2)]), FUN=function(alg){ 
    ifelse(env_preds[,alg]&gt;=comp_perf[comp_perf$alg==alg,&#39;thresh&#39;],1,0)
  }))

# Make rasters from predictions:
r_preds &lt;- rasterFromXYZ(env_preds, crs=crs(bg))
r_preds_bin &lt;- rasterFromXYZ(env_preds_bin, crs=crs(bg))

# Map predicted occurrence probabilities:
spplot(r_preds)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code># Map predicted presences:
spplot(r_preds_bin)</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-20-2.png" width="672" /></p>
<p>Now, we map the ensemble predictions.</p>
<pre class="r"><code># We make ensembles:    
env_ensemble &lt;- data.frame(bio_curr_df[,1:2], 
  mean_prob = rowMeans(env_preds[,-c(1:2)]),
  median_prob = apply(env_preds[,-c(1:2)], 1, median),
  wmean_prob = apply(env_preds[,-c(1:2)], 1, weighted.mean, w=comp_perf[,&#39;TSS&#39;]),
  committee_av = rowSums(env_preds_bin[,-c(1:2)])/ncol(env_preds_bin[,-c(1:2)]),
  sd_prob = apply(env_preds[,-c(1:2)], 1, sd))

# Make rasters from ensemble predictions:
r_ens &lt;- rasterFromXYZ(env_ensemble, crs=crs(bg))

# Map continuous ensemble predictions:
spplot(r_ens[[1:4]])</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Mapping the standard deviation of model predictions shows us the
areas of highest deviation between model algorithms.</p>
<pre class="r"><code># Map standard deviation across model algorithms:
plot(r_ens[[&#39;sd_prob&#39;]])</code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>We can also derive binary ensemble predictions. We have already
estimated the optimal thresholds when calculating the performance
measures for the ensembles.</p>
<pre class="r"><code># Binarise ensemble predictions
env_ensemble_bin &lt;- data.frame(bio_curr_df[,1:2], 
    sapply(c(&#39;mean_prob&#39;, &#39;median_prob&#39;, &#39;wmean_prob&#39;), 
           FUN=function(x){ifelse(env_ensemble[,x]&gt;= ens_perf[x,&#39;thresh&#39;],1,0)}))

# Make rasters:
r_ens_bin &lt;- rasterFromXYZ(env_ensemble_bin, crs=crs(bg))

# Map predicted presence from ensembles:
spplot(r_ens_bin)   </code></pre>
<p><img src="7_SDM_algorithms_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
</div>
</div>
<div id="outlook" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Outlook</h1>
<p>We have now fitted multiple SDM algorithms to our species
distribution data and made predictions in space and time. Of course,
science doesn’t stop here and you may want to answer different questions
using the SDM. I only provide some hints here.</p>
<div class="alert alert-success">
<p>In conservation, we often aim to prioritise the most important sites
for reserve selection.</p>
<ul>
<li>Identify the top 5 % suitable area (the 5 % of cells with the
highest habitat suitability)</li>
<li>Compare the top 5 % suitable area across different SDM
algorithms</li>
<li>Overlay the top 5 % suitable area for multiple species (if you
fitted SDMs to multiple species)</li>
</ul>
<p>Some more advanced questions could analyse biodiversity changes. For
example:</p>
<ul>
<li>Make predictions to future climate layers and compare how much the
lynx is predicted to win or lose in range size under climate change and
how this prediction varies across model algorithms?</li>
<li>Where is your species range predicted to remain stable, to become
unsuitable or to become colonisable under climate change? (Hints how to
visualise this can be found in our <a
href="https://damariszurell.github.io/EEC-MGC/a6_BiodivChanges.html">Macroecology
practicals</a>)</li>
</ul>
<p>What other ideas do you have?</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-araujo2007" class="csl-entry">
Araujo, M. B., and M. New. 2007. <span>“Ensemble Forecasting of Species
Distributions.”</span> <em>Trends in Ecology and Evolution</em> 22:
42–47.
</div>
<div id="ref-Booth2014" class="csl-entry">
Booth, T. H., H. A. Nix, J. R. Busby, and M. F. Hutchinson. 2014.
<span>“Bioclim: The First Species Distribution Modelling Package, Its
Early Applications and Relevance to Most Current MaxEnt Studies.”</span>
<em>Diversity and Distributions</em> 20: 1–9.
</div>
<div id="ref-BUISSON2010" class="csl-entry">
Buisson, L., W. Thuiller, N. Casajus, S. Lek, and G. Grenouillet. 2010.
<span>“Uncertainty in Ensemble Forecasting of Species
Distribution.”</span> <em>Global Change Biology</em> 16: 1145–57.
</div>
<div id="ref-Dormann2018a" class="csl-entry">
Dormann, C. F., J. M. Calabrese, G. Guillera-Arroita, E. Matechou, V.
Bahn, K. Barton, C. M. Beale, et al. 2018. <span>“Model Averaging in
Ecology: A Review of Bayesian, Information-Theoretic, and Tactical
Approaches for Predictive Inference.”</span> <em>Ecological
Monographs</em> 88 (4): 485–504. <a
href="https://doi.org/10.1002/ecm.1309">https://doi.org/10.1002/ecm.1309</a>.
</div>
<div id="ref-elith2006" class="csl-entry">
Elith, J., C. H. Graham, R. P. Anderson, M. Dudik, S. Ferrier, A.
Guisan, R. J. Hijmans, et al. 2006. <span>“Novel Methods Improve
Prediction of Species’ Distribution from Occurence Data.”</span>
<em>Ecography</em> 29: 129–51.
</div>
<div id="ref-elith2008" class="csl-entry">
Elith, J., J. R. Leathwick, and T. Hastie. 2008. <span>“A Working Guide
to Boosted Regression Trees.”</span> <em>Journal of Animal Ecology</em>
77: 802–13.
</div>
<div id="ref-Guisan2017" class="csl-entry">
Guisan, A., W. Thuiller, and N. E. Zimmermann. 2017. <em>Habitat
Suitability and Distribution Models with Applications in r</em>.
Cambride University Press.
</div>
<div id="ref-Hastie2009" class="csl-entry">
Hastie, T., R. Tibshirani, and J. Friedman. 2009. <em>The Elements of
Statistical Learning</em>. Springer.
</div>
<div id="ref-hutchinson1957" class="csl-entry">
Hutchinson, G. E. 1957. <span>“Concluding Remarks, Cold Spring Harbor
Symposium.”</span> <em>Quantitative Biology</em> 22: 415–27.
</div>
<div id="ref-Thuiller2019" class="csl-entry">
Thuiller, W., M. Guéguen, J. Renaud, D. N. Karger, and N. E. Zimmermann.
2019. <span>“Uncertainty in Ensembles of Global Biodiversity
Scenarios.”</span> <em>Nature Communications</em> 10: 1446.
</div>
<div id="ref-Thuiller2009" class="csl-entry">
Thuiller, W., B. Lafourcade, R. Engler, and M. B. Araujo. 2009.
<span>“BIOMOD - a Platform for Ensemble Forecasting of Species
Distributions.”</span> <em>Ecography</em> 32: 369–73.
</div>
<div id="ref-Vuuren2013" class="csl-entry">
Vuuren, D. P. van, and T. R. Carter. 2013. <span>“Climate and
Socio-Economic Scenarios for Climate Change Research and Assessment:
Reconciling the New with the Old.”</span> <em>Climatic Change</em> 122
(November): 415–29.
</div>
<div id="ref-Zurell2020a" class="csl-entry">
Zurell, D., J. Franklin, C. König, P. J. Bouchet, C. F. Dormann, J.
Elith, G. Fandos, et al. 2020. <span>“A Standard Protocol for Reporting
Species Distribution Models.”</span> <em>Ecography</em> 43 (9): 1261–77.
<a
href="https://doi.org/10.1111/ecog.04960">https://doi.org/10.1111/ecog.04960</a>.
</div>
<div id="ref-Zurell2020" class="csl-entry">
Zurell, D., N. E. Zimmermann, H. Gross, A. Baltensweiler, T. Sattler,
and R. O. Wüest. 2020. <span>“Testing Species Assemblage Predictions
from Stacked and Joint Species Distribution Models.”</span> <em>Journal
of Biogeography</em> 47 (1): 101–13. <a
href="https://doi.org/10.1111/jbi.13608">https://doi.org/10.1111/jbi.13608</a>.
</div>
</div>
</div>

<!DOCTYPE html>
<html>

<br>
<hr />
<div id="footer">
<p>Damaris Zurell 2022 <a href="http://creativecommons.org/licenses/by/4.0/" >(CC BY 4.0)</a>.  </p>
</div>

</html>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
